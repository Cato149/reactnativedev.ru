---
description: Чтобы мобильные приложения казались пользователю более естественными, мы используем анимацию для сглаживания взаимодействия пользователя с пользовательским интерфейсом приложения
---

# События

В реальном мире ничего не меняется мгновенно - всегда есть что-то между состояниями. Когда мы прикасаемся к книге, мы не ожидаем, что она мгновенно откроется на определенной странице. Чтобы мобильные приложения казались пользователю более естественными, мы используем анимацию для сглаживания взаимодействия пользователя с пользовательским интерфейсом приложения.

Чтобы показать, как происходит обработка событий в Reanimated, мы шаг за шагом приведем вас к следующему результату:

![Результат](final.gif)

## Обработка событий жестов

Reanimated тесно интегрируется с пакетом [react-native-gesture-handler](https://docs.swmansion.com/react-native-gesture-handler/), позволяющим определять эффективные взаимодействия, основанные на жестах. Мы объясняем API библиотеки всякий раз, когда используем ее части в наших примерах, однако если вы хотите узнать больше о gesture-handler вне контекста reanimated, посетите сайт документации [здесь](https://docs.swmansion.com/react-native-gesture-handler/).

Для Android OS обязательно оберните точку входа в приложение компонентом `<GestureHandlerRootView>` из библиотеки `react-native-gesture-handler`, чтобы правильно перехватывать события.

```js
import { GestureHandlerRootView } from 'react-native-gesture-handler';

export default function App() {
    return (
        <GestureHandlerRootView style={{ flex: 1 }}>
            {/* content */}
        </GestureHandlerRootView>
    );
}
```

Возвращаясь к примеру взаимодействия, начнем с того, что сосредоточимся только на событиях касания.

![События касания](touch-final.gif)

```js
const EventsExample = () => {
    const pressed = useSharedValue(false);
    return (
        <TapGestureHandler onGestureEvent={eventHandler}>
            <Animated.View style={[styles.ball]} />
        </TapGestureHandler>
    );
};
```

Здесь мы определяем компонент с общим значением, которое сообщает нам, нажимают ли на отрисовываемый вид. Мы используем компонент `TapGestureHandler` из библиотеки `react-native-gesture-handler` для обертывания основного `View`, чтобы сообщить фреймворку, какие из отрисованных элементов являются интерактивными.

Далее мы добавим к нему обработчик событий - он будет реагировать на уведомления о событиях касания от `TapGestureHandler`. Для определения обработчиков событий в Reanimated предусмотрен хук, специально предназначенный для работы с пакетом `gesture-handler`, он называется `useAnimatedGestureHandler`.

```js
const eventHandler = useAnimatedGestureHandler({
    onStart: (event, ctx) => {
        pressed.value = true;
    },
    onEnd: (event, ctx) => {
        pressed.value = false;
    },
});
```

Этот хук позволяет определить несколько воркетов (например, `onStart` или `onEnd`), каждый из которых будет использоваться для обработки различных состояний в процессе распознавания жестов. В данном примере мы будем использовать заготовку `onStart`, которая вызывается при начале жеста (нажатии на экран вниз), и `onEnd`, которая запускается при завершении жеста (т.е. при отрыве пальца от экрана). С помощью этих двух обработчиков мы соответствующим образом обновляем разделяемое значение `pressed` (не обращайте внимания на аргументы, которые передаются обработчикам, об этом мы расскажем позже).

Чтобы связать определенный обработчик событий с компонентом обработчика жестов, мы передаем его в `TapGestureHandler` в качестве свойства `onGestureEvent`:

```js
<TapGestureHandler onGestureEvent={eventHandler}>
```

Теперь осталось только использовать хук `useAnimatedStyle`, чтобы сопоставить состояние общего значения `pressed` со стилями представления. При истинном нажатии цвет точки изменится с _синего_ на _желтый_ и она станет больше. При значении `false` оба этих параметра вернутся к прежним значениям.

```js
const uas = useAnimatedStyle(() => {
    return {
        backgroundColor: pressed.value
            ? '#FEEF86'
            : '#001972',
        transform: [{ scale: pressed.value ? 1.2 : 1 }],
    };
});
```

Также не забудьте передать _animated style_ в _animated view_:

```js
<Animated.View style={[styles.ball, uas]} />
```

После внесения описанных выше изменений вот что вы увидите на экране:

![События касания](touch-raw.gif)

В Reanimated очень легко создавать анимацию между изменениями состояния. Вы можете попробовать добавить `withSpring` или `withTiming` в `useAnimatedStyle`, чтобы сделать это взаимодействие более естественным:

```js
{
    scale: withSpring(pressed.value ? 1.2 : 1);
}
```

![События касания](touch-final.gif)

## Обработка непрерывных жестов

![Обработка непрерывных жестов](final.gif)

В предыдущем примере, когда мы учились обрабатывать жесты касания, мы реагировали только на события, указывающие на начало и конец жеста. Это объясняется тем, что касание - дискретный жест, то есть он срабатывает в определенный момент времени, когда мы знаем, что жест распознан. Если же нас интересует обработка движения пальца по экрану, то нам необходимо получать непрерывный поток событий касания. Для этого можно использовать `PanGestureHandler` из пакета `react-native-gesture-handler`. `PanGestureHandler` не только сообщает о событиях "вниз" и "вверх" (на которые мы подписались с помощью ворклетов `onStart` и `onEnd`), но и позволяет отслеживать палец при его панорамировании по экрану. При распознавании жеста панорамирования в обратный вызов `onActive` подается поток событий касания в течение всего времени взаимодействия с пользователем.

![Обработка непрерывных жестов](continous-gestures.png)

Для того чтобы отслеживать перемещение вида, мы определяем пару новых общих значений, в которых будем хранить координаты вида:

```js
const startingPosition = 100;
const x = useSharedValue(startingPosition);
const y = useSharedValue(startingPosition);
```

Теперь, чтобы синхронизировать определенные выше значения с жестом, мы модифицируем поведение `useAnimatedGestureHandler`.

```js
const eventHandler = useAnimatedGestureHandler({
    onStart: (event, ctx) => {
        pressed.value = true;
    },
    onActive: (event, ctx) => {
        x.value = startingPosition + event.translationX;
        y.value = startingPosition + event.translationY;
    },
    onEnd: (event, ctx) => {
        pressed.value = false;
        x.value = withSpring(startingPosition);
        y.value = withSpring(startingPosition);
    },
});
```

В методе `onActive` мы обновляем координаты, используя полезную нагрузку события, которая предоставляется в качестве первого аргумента. Мы используем `translationX` и `translationY`, которые указывают положение пальца относительно того места на экране, где началось панорамирование. В вызове `onEnd`, когда пользователь отпустит палец, мы анимируем координаты до начальной позиции.

Не забудьте передать модифицированный обработчик события `PanGestureHandler`:

```js
<PanGestureHandler onGestureEvent={eventHandler}>
    <Animated.View style={[styles.ball, uas]} />
</PanGestureHandler>
```

Осталось только обновить тело `useAnimatedStyle` таким образом, чтобы общие значения `x` и `y` были привязаны к трансформациям представления для позиционирования нашего представления на экране:

```js
const uas = useAnimatedStyle(() => {
    return {
        backgroundColor: pressed.value
            ? '#FEEF86'
            : '#001972',
        transform: [
            { translateX: x.value },
            { translateY: y.value },
        ],
    };
});
```

## Использование контекста

![Использование контекста](context-gesture.gif)

Теперь попробуем модифицировать приведенный выше пример так, чтобы вид оставался в том месте, где мы поднимаем палец вверх, а затем позволял панорамировать его из этого места. Эта простая модификация становится немного сложнее, и причина заключается в том, что при запуске нового жеста значения перевода, которые он предоставляет в полезной нагрузке события, относятся к начальной позиции жеста. В результате мы не можем просто напрямую сопоставить перевод жеста со смещением вида на экране. Одним из способов решения этой проблемы является создание временного состояния, в котором мы можем хранить начальное смещение вида. Для этого мы можем использовать аргумент context, который предоставляется каждому из обработчиков жестов. Контекст - это просто объект Javascript, который разделяется между всеми обратными вызовами. Другими словами, все методы, определенные как обратные вызовы обработчиков жестов, получают один и тот же экземпляр объекта context - вы можете хранить в нем любые данные внутри обратного вызова или читать из контекста напрямую.

Вот как мы можем сохранить начальную позицию в обратном вызове `onStart`, используя контекст:

```js
onStart: (event, ctx) => {
  pressed.value = true;
  ctx.startX = x.value;
  ctx.startY = y.value;
},
```

Затем мы можем использовать его в `onActive` для вычисления текущей позиции

```js
onActive: (event, ctx) => {
  x.value = ctx.startX + event.translationX;
  y.value = ctx.startY + event.translationY;
},
```

Как видите, контекст может быть очень удобен, избавляя нас от объявления дополнительных переменных в коде и делая его более понятным.

## Reanimated и react-native-gesture-handler

Вы уже познакомились с `TapGestureHandler` и `PanGestureHandler`, но существует множество других. Например, с помощью `PinchGestureHandler` можно прослушивать жесты щипка. Он позволяет отслеживать расстояние между двумя пальцами и использовать эту информацию для масштабирования или увеличения содержимого. Полный список доступных обработчиков жестов можно найти [здесь](https://docs.swmansion.com/react-native-gesture-handler/docs/gesture-handlers/basics/about-handlers#available-gesture-handlers).

<iframe width="100%" height="400" gesture="media"  allow="encrypted-media" allowfullscreen src="https://www.youtube.com/embed/IdVnnIkNzGA">
</iframe>

## Ссылки

-   [Events](https://docs.swmansion.com/react-native-reanimated/docs/fundamentals/events/)
